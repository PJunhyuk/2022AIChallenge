# 2022AIChallenge

λ³Έ repoλ” *λ§μ΄μ• λ―Έ* ν€μ 2022 μΈκ³µμ§€λ¥ μ¨λΌμΈ κ²½μ§„λ€ν μ¤‘ *μ£Όμ°¨ κ΄€λ ¨ μ΄λ™μ²΄ κ°μ²΄ κ²€μ¶ λ¬Έμ * νƒμ¤ν¬ μν–‰μ„ μ„ν• λ ν¬μ§€ν† λ¦¬μ…λ‹λ‹¤.  

- - -

## μ…‹μ—…

ν•™μµ λ° μ¶”λ΅ μ„ μ„ν• ν™κ²½μ„ κµ¬μ¶•ν•λ” λ‹¨κ³„μ…λ‹λ‹¤.  

### λ³„λ„ μ…‹μ—…

λ³„λ„μ ν™κ²½μ„ μ„ν• μ…‹μ—… κ³Όμ •μ…λ‹λ‹¤. μ¬ν„μ„± κ²€μ¦ μ„λ²„μ—μ„λ” κ°€μƒν™κ²½ μ„¤μ • μ—†μ΄ μ§μ ‘ λΌμ΄λΈλ¬λ¦¬λ¥Ό μ„¤μΉν•μ—¬ μ‚¬μ©ν•κΈ° λ•λ¬Έμ— λ³Έ κ³Όμ •μ€ μƒλµν•©λ‹λ‹¤.  
λ‹¤λ¥Έ μ„λ²„λΌλ„ docker κ°€ μ„¤μΉλμ–΄ μκ³ , dataset μ΄ μ•λ§μ€ κ²½λ΅μ— μ¤€λΉ„λμ–΄ μλ‹¤λ©΄ μƒλµν•  μ μμµλ‹λ‹¤.  

#### docker μ„¤μΉ

λ³Έ repo λ” κ°„νΈν• μ„¤μΉλ¥Ό μ„ν•΄ `docker` λ¥Ό κ¶μ¥ν•©λ‹λ‹¤. μ„λ²„μ— `docker` κ°€ μ„¤μΉλμ–΄ μμ§€ μ•μ€ κ²½μ° λ‹¤μκ³Ό κ°™μ€ λ°©μ‹μΌλ΅ μ„¤μΉ κ°€λ¥ν•©λ‹λ‹¤.  

```bash
$ sudo apt-get remove docker docker-engine docker.io
$ sudo apt-get update && sudo apt-get install apt-transport-https ca-certificates curl software-properties-common
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

$ sudo apt-get update && sudo apt-cache search docker-ce
# Message: docker-ce - Docker: the open-source application container engine

$ sudo apt-get update && sudo apt-get install docker-ce
$ sudo usermod -aG docker $USER

$ curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
$ curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

$ sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
$ sudo systemctl restart docker
```

λ„μ¤‘μ— `sudo: unable to resolve host` μ—λ¬κ°€ λ‚μ¤λ©΄ [λ§ν¬](https://extrememanual.net/33739) λ΅ ν•΄κ²°ν•λ©΄ λ©λ‹λ‹¤.

#### docker λ° git, ffmpeg (for opencv) μ„Έν…

μ—¬λ¬ docker image μ¤‘ `nvidia/pytorch` μ κΈ°λ³Έ μ΄λ―Έμ§€λ¥Ό ν™μ©ν•©λ‹λ‹¤. λ‹¤μκ³Ό κ°™μ€ λ°©μ‹μΌλ΅ docker λ¥Ό κ°€μ Έμµλ‹λ‹¤.  

```bash
$ docker pull nvcr.io/nvidia/pytorch:20.12-py3
$ docker run --gpus all --name 2022AIChallenge --shm-size 8G -v ~/workspace/code:/root/workspace/code -v /DATA:/DATA -it nvcr.io/nvidia/pytorch:20.12-py3
```

#### κ³Όμ  λ°μ΄ν„° λ‹¤μ΄λ΅λ“ λ° μ…‹μ—…

μ κ³µλ λ°μ΄ν„°λ” `/DATA` λ””λ ‰ν† λ¦¬μ— λ‹¤μκ³Ό κ°™μ€ ν•νƒλ΅ μ¤€λΉ„λμ–΄μμμ„ μ „μ ν•©λ‹λ‹¤. (μ¬ν„μ„± κ²€μ¦ μ„λ²„ κΈ°μ¤€)  

```
/DATA
|-- test/
    |-- images/
        |-- 0dbc1884-9895-4294-91ef-77626a5ca826.png
        |-- ...
|-- train/
    |-- images/
        |-- 20201102_κ²½κΈ°λ„_-_-_λ§‘μ_μ£Όκ°„_μ‹¤μ™Έ_right_000079_0088055.png
        |-- ...
    |-- label/
        |-- Train.json
|-- sample_submission.json
|-- Test_Images_Information.json
|-- test.zip
|-- train.zip
```

### μ„Έλ¶€ ν™κ²½ μ„Έν…

κΈ°λ³Έ package μΈ git κ³Ό ffmpeg λ¥Ό μ„¤μΉν•΄μ•Ό ν•©λ‹λ‹¤.  

```bash
# Install git & ffmpeg
# 'glib2' is a dependency of 'opencv'
# type 6-69-6
$ apt-get update && apt-get install -y --no-install-recommends \
    git libxrender1 ffmpeg libglib2.0-0 && \
    rm -rf /var/lib/apt/lists/*
```

λ„μ¤‘μ— `GPG error` κ°€ λ°μƒν•λ©΄ [λ§ν¬](https://eehoeskrap.tistory.com/454) λ΅ ν•΄κ²°ν•λ©΄ λ©λ‹λ‹¤.  

#### μ‘μ—… ν΄λ” μ„Έν…

μ‘μ—… ν΄λ”λ¥Ό μ„Έν…ν•κΈ° μ„ν•΄ μ μ¶ν• μ½”λ“λ¥Ό `/USER` λ””λ ‰ν† λ¦¬μ— μ„Έν…ν•©λ‹λ‹¤.  
νΉμ€ λ‹¤μκ³Ό κ°™μ΄ `git` μ—μ„ κ°€μ Έμµλ‹λ‹¤.  

```bash
(/USER) $ git clone https://github.com/PJunhyuk/2022AIChallenge
```

** μ΄ν›„μ λ¨λ“  μ½”λ“λ” νΉλ³„ν• μ–ΈκΈ‰μ΄ μ—†λ‹¤λ©΄ current work directory(`/USER/2022AIChallenge`) ν•μ—μ„μ μ‹¤ν–‰μ„ μ „μ ν•©λ‹λ‹¤.  

#### dependencies μ„¤μΉ

μ¬ν„μ„± κ²€μ¦ μ„λ²„μ—μ„λ” μ΄ν›„ λ¨λ“  μ½”λ“λ¥Ό Jupyter λ…ΈνΈλ¶ Terminal μ—μ„μ μ‹¤ν–‰μ„ μ „μ ν•©λ‹λ‹¤.  

```bash
$ pip install -r requirements.txt
```

- - -

## ν•™μµ λ° μ¶”λ΅ 

### ν•™μµ

```bash
$ python train.py
```

> μ£Όμ! baseline ν•™μµ ν›„ finetuning κ³Όμ •μ—μ„ pre-trained weights λ΅ μ‚¬μ©ν•λ” κ°€μ¤‘μΉ νμΌμ κ²½λ΅κ°€ `runs/train/official/weights/last.pt` λ΅ ν•λ“μ½”λ”© λμ–΄ μμµλ‹λ‹¤. μµμ΄ μ‹¤ν–‰ λ•λ” λ¬Έμ κ°€ μ—†μ§€λ§, λ°λ³µ μ‹¤ν–‰ν•μ—¬ baseline ν•™μµ ν›„ μƒμ„±λλ” ν΄λ”κ°€ `runs/train/official7` μ‹μΌλ΅ λ³€κ²½λλ‹¤λ©΄ μ΄ λ¶€λ¶„μ„ λ³€κ²½ν•΄μ£Όμ–΄μ•Ό ν•©λ‹λ‹¤. μ΄λ” `train.py` μ½”λ“μ 661λ²μ§Έ μ¤„μ—μ„ λ³€κ²½ν•μ‹¤ μ μμµλ‹λ‹¤.

> νΉμ€ μ•„μ λ§¤ μ‹¤ν–‰ μ „ `$ rm -r runs/` λ…λ Ήμ–΄λ΅ `runs` κ²½λ΅λ¥Ό μ΄κΈ°ν™”ν•΄μ¤λ„ κ΄μ°®μµλ‹λ‹¤.

### μ¶”λ΅ 

```bash
$ python predict.py
```

- - -

## μƒμ„Έ μ„¤λ…

repo μ „λ°μ— λ€ν• μƒμ„Έ μ„¤λ…μ…λ‹λ‹¤.  

### μ½”λ“ μƒμ„Έ μ„¤λ…

μ μ¶ν• μ½”λ“λ” λ‹¤μκ³Ό κ°™μ€ ν•νƒλ΅ μ΄λ£¨μ–΄μ Έ μμµλ‹λ‹¤.  

```
/USER/2022AIChallenge
|-- data/
    |-- hyps/
	    |-- hyp.finetune.yaml
        |-- hyp.scratch-low.yaml
	|-- dataset.yaml
|-- models/
    |-- ...
|-- utils/
    |-- ...
|-- predict.py
|-- README.md
|-- requirements.txt
|-- train.py
|-- val.py
```

#### `submission` ν΄λ” μ„¤λ…

`submission` ν΄λ”μ—λ” μµκ³ μ  μ μ¶λ¬Όμ— λ€μ‘ν•λ” νμΌλ“¤μ΄ λ‹΄κ²¨ μμµλ‹λ‹¤. κ°κ°μ— λ€ν• μ„¤λ…μ€ λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.  

- `baseline_last.pt` : yolov5x6.pt μ—μ„ hyp.scratch-low.yaml μ„ κΈ°λ°μΌλ΅ 50 epoch ν•™μµν• λ¨λΈ κ°€μ¤‘μΉ νμΌμ…λ‹λ‹¤. μƒλ΅­κ² train ν•λ‹¤λ©΄ μ–»μ„ μ μλ” `runs/train/official/weights/last.pt` νμΌμ— ν•΄λ‹Ήν•©λ‹λ‹¤.
- `tune_last.pt` : baseline_last.pt μ—μ„ hyp.finetune.yaml μ„ κΈ°λ°μΌλ΅ 15 epoch μ¶”κ°€ ν•™μµν• λ¨λΈ κ°€μ¤‘μΉ νμΌμ…λ‹λ‹¤. μƒλ΅­κ² train ν•λ‹¤λ©΄ μ–»μ„ μ μλ” `runs/train/official2/weights/last.pt` νμΌμ— ν•΄λ‹Ήν•©λ‹λ‹¤. **μµκ³ μ  μ μ¶λ¬Όμ— λ€μ‘ν•λ” λ¨λΈ κ°€μ¤‘μΉ νμΌμ…λ‹λ‹¤.**
- `best_preds_cut.json` : **μµκ³ μ  Submission νμΌμ…λ‹λ‹¤.**

λ‹¤μμ λ…λ Ήμ–΄λ¥Ό ν†µν•΄ `tune_last.pt` μ—μ„ `best_preds_cut.json` μ„ μƒμ„±ν•λ” μ¶”λ΅  κ³Όμ •μ„ μ§μ ‘ μ¬ν„ν•  μ μμµλ‹λ‹¤.  

```bash
$ python predict.py --weights submission/tune_last.pt
```

### `train.py` μ„¤λ…

λ¨λΈ ν•™μµμ— μ‚¬μ©λλ” python νμΌμ…λ‹λ‹¤.  

#### 1. dataset ν΄λ” μƒμ„± λ° μ„Έν…

`train.py` λ¥Ό μ‹¤ν–‰ν•λ©΄ μ°μ„  ν•™μµμ— μ‚¬μ©ν•  λ°μ΄ν„°μ…‹ ν΄λ”λ¥Ό μƒμ„±ν•κ³  μ„Έν…ν•λ” μ μ°¨κ°€ μ§„ν–‰λ©λ‹λ‹¤. `train.py` μ `data_prepare()` ν•¨μλ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. `/DATA` ν΄λ”μ λ°μ΄ν„°λ¥Ό μ½μ–΄ `../dataset/` ν΄λ”μ— ν•™μµμ— μ ν•©ν• ν•νƒλ΅ μ΄λ―Έμ§€λ¥Ό λ³µμ‚¬ν•μ—¬ μ„Έν…ν•κ³ , ν•™μµμ— μ ν•©ν• ν•νƒλ΅ label νμΌλ“¤μ„ μƒμ„±ν•©λ‹λ‹¤. μ¬ν„μ„± κ²€μ¦ μ„λ²„ κΈ°μ¤€ 30λ¶„ μ •λ„ μ†μ”λ©λ‹λ‹¤.  

```
data preparing
generate raw_train.json, raw_val.json
100%|β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 134741/134741 [00:24<00:00, 5574.02it/s]
generate dataset/train, dataset/val
100%|β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 16258/16258 [04:45<00:00, 56.95it/s]
100%|β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 118483/118483 [28:13<00:00, 69.97it/s]
100%|β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 19521/19521 [00:00<00:00, 1632512.03it/s]
```

μµμ΄ ν•™μµ μ΄ν›„ λ‹¤μ‹ ν•™μµν•  λ•λ” μ΄λ―Έ `../dataset/` ν΄λ”κ°€ μƒμ„±λμ–΄ μκΈ° λ•λ¬Έμ—, μ΄ κ³Όμ •μ„ λ°λ³µν•  ν•„μ”κ°€ μ—†μµλ‹λ‹¤. `--no-data-prepare` ν”λκ·Έλ΅ μ΄ κ³Όμ •μ„ μƒλµν•  μ μμµλ‹λ‹¤.  

```bash
$ python train.py --no-data-prepare
```

#### 2. baseline ν•™μµ

μ°μ„  yolov5x6.pt pre-trained weight μ„ μ‚¬μ©ν•μ—¬ baseline ν•™μµμ„ μ§„ν–‰ν•©λ‹λ‹¤. flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ λ‹¤μμ μ£Όμ” args λ“¤μ΄ default λ΅ μ„¤μ •λμ–΄ μμµλ‹λ‹¤.  

```
--weights yolov5x6.pt
--epochs 50
--epoch-parts 15
--batch-size 2
--image-weights True
--imgsz 1280
--hyp data/hyps/hyp.scratch-low.yaml
```

μ¬ν„μ„± κ²€μ¦ μ„λ²„ κΈ°μ¤€ ν• epoch ν•™μµμ— 30λ¶„ μ •λ„ μ†μ”λ©λ‹λ‹¤. 50 epoch μ„ ν•™μµν•κΈ° λ•λ¬Έμ— μ „μ²΄λ΅λ” 26μ‹κ°„ μ •λ„ μ†μ”λ©λ‹λ‹¤.  

```bash
train: weights=yolov5x6.pt, data=data/dataset.yaml, epochs=50, epoch_parts=15, batch_size=2, no_image_weights=False, imgsz=1280, hyp=data/hyps/hyp.scratch-low.yaml, val_period=0, no_data_prepare=False, path_DATA_dir=/DATA, project=runs/train, name=final, cfg=, rect=False, resume=False, nosave=False, noautoanchor=False, noplots=False, bucket=, cache=None, device=, multi_scale=False, optimizer=SGD, sync_bn=False, workers=8, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, image_weights=True, noval=True
hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5x6.pt to yolov5x6.pt...
100%|β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 270M/270M [00:52<00:00, 5.41MB/s]
Scaled weight_decay = 0.0005
optimizer: SGD with parameter groups 159 weight (no decay), 163 weight, 163 bias

AutoAnchor: 6.10 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset β…
Image sizes 1280 train, 1280 val
Using 2 dataloader workers
Logging results to runs/train/final
Starting training for 50 epochs...

     Epoch   gpu_mem       box       obj       cls    labels  img_size
      0/49     14.1G   0.07297   0.07933   0.05713        29      1280: 100%|β–β–β–β–β–β–β–β–β–β–| 721/721 [30:20<00:00,  2.52s/it]

     Epoch   gpu_mem       box       obj       cls    labels  img_size
      1/49     14.1G    0.0594   0.04674   0.04433        18      1280: 100%|β–β–β–β–β–β–β–β–β–β–| 721/721 [30:23<00:00,  2.53s/it]
```

flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ output μ€ λ‹¤μκ³Ό κ°™μ€ ν•νƒλ΅ μƒμ„±λ©λ‹λ‹¤.

```
/USER/2022AIChallenge
|-- runs/
    |-- train/
        |-- official/
            |-- weights/
                |-- best.pt
                |-- last.pt
            |-- ...
```

#### 3. finetuning ν•™μµ

μ°μ„  μ„ baseline ν•™μµμ„ ν†µν•΄ μƒμ„±λ last.pt λ¥Ό pre-trained weight μΌλ΅ μ‚¬μ©ν•μ—¬ finetuning ν•™μµμ„ μ§„ν–‰ν•©λ‹λ‹¤. flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ λ‹¤μμ μ£Όμ” args λ“¤μ΄ default λ΅ μ„¤μ •λμ–΄ μμµλ‹λ‹¤.  

```
--weights runs/train/official/weights/last.pt
--epochs-tune 15
--epoch-parts 15
--batch-size 2
--image-weights False
--imgsz 1280
--hyp-tune data/hyps/hyp.finetune.yaml
```

μ¬ν„μ„± κ²€μ¦ μ„λ²„ κΈ°μ¤€ ν• epoch ν•™μµμ— 30λ¶„ μ •λ„ μ†μ”λ©λ‹λ‹¤. 15 epoch μ„ ν•™μµν•κΈ° λ•λ¬Έμ— μ „μ²΄λ΅λ” 8μ‹κ°„ μ •λ„ μ†μ”λ©λ‹λ‹¤.  

flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ output μ€ λ‹¤μκ³Ό κ°™μ€ ν•νƒλ΅ μƒμ„±λ©λ‹λ‹¤.

```
/USER/2022AIChallenge
|-- runs/
    |-- train/
        |-- official2/
            |-- weights/
                |-- best.pt
                |-- last.pt
            |-- ...
```

μµμΆ… μƒμ„±λ `runs/train/official2/weights/best.pt` νμΌμ΄ μµκ³ μ  μ μ¶λ¬Όμ— λ€μ‘ν•λ” λ¨λΈ κ°€μ¤‘μΉ νμΌμ…λ‹λ‹¤.  

μ„ κ³Όμ •λ“¤μ„ λ¨λ‘ ν¬ν•¨ν• ν•™μµμ— μ†μ”λ μ΄ μ‹κ°„μ€ μ¬ν„μ„± κ²€μ¦ μ‹κ°„ κΈ°μ¤€ 34.5μ‹κ°„ μ •λ„λ΅, 36μ‹κ°„ μ ν•μ„ μ¶©μ΅±ν•©λ‹λ‹¤.  

### `predict.py` μ„¤λ…

λ¨λΈ μ¶”λ΅ μ— μ‚¬μ©λλ” python νμΌμ…λ‹λ‹¤.  

#### 1. λ¨λΈ μ¶”λ΅ 

`predict.py` λ¥Ό μ‹¤ν–‰ν•λ©΄ μ°μ„  μ£Όμ–΄μ§„ weights λ΅ μ¶”λ΅ μ„ μ§„ν–‰ν•©λ‹λ‹¤. flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ λ‹¤μμ μ£Όμ” args λ“¤μ΄ default λ΅ μ„¤μ •λμ–΄ μμµλ‹λ‹¤.  

```
--weights runs/train/official2/weights/best.pt
--batch-size 16
--iou-thres 0.7
--imgsz 1536
```

flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ `runs/val/official/` κ²½λ΅μ— Submission ν•μ‹κ³Ό λ§λ” `best_preds.json` νμΌμ„ μƒμ„±ν•©λ‹λ‹¤.  

#### 2. conf cut

Submission νμΌμ 20MB μ©λ‰ μ ν•μ„ ν”Όν•κΈ° μ„ν•΄, μ©λ‰μ΄ 20MB λ³΄λ‹¤ μ‘μ§€λ§ κ°€μ¥ κ·Όμ ‘ν• Submission νμΌ μƒμ„±μ„ μ„ν• conf cut κ°’μ„ μ°Ύλ” κ³Όμ •μ…λ‹λ‹¤. `runs/val/official/` κ²½λ΅μ— Submission ν•μ‹κ³Ό λ§κ³  μ©λ‰μ΄ 20MB λ³΄λ‹¤ λ‚®μ€ `best_preds_cut.json` νμΌμ„ μƒμ„±ν•©λ‹λ‹¤. **μ΄κ²ƒμ΄ μµκ³ μ  μ μ¶λ¬Όμ— λ€μ‘ν•λ” Submission νμΌμ΄ λ©λ‹λ‹¤.**  

flag μ—†μ΄ μ‹¤ν–‰ν•λ‹¤λ©΄ output μ€ λ‹¤μκ³Ό κ°™μ€ ν•νƒλ΅ μƒμ„±λ©λ‹λ‹¤.  

```
/USER/2022AIChallenge
|-- runs/
    |-- val/
        |-- official/
            |-- best_preds_cut.json
            |-- best_preds.json
```

μ¬ν„μ„± κ²€μ¦ μ„λ²„ κΈ°μ¤€ μ¶”λ΅ μ—λ” 2μ‹κ°„ μ •λ„κ°€ μ†μ”λ©λ‹λ‹¤. conf cut κ³Όμ •μ€ 10λ¶„ λ―Έλ§μΌλ΅ μ†μ”λλ―€λ΅, μ„ κ³Όμ •μ„ λ¨λ‘ ν¬ν•¨ν• μ¶”λ΅ μ— μ†μ”λ μ΄ μ‹κ°„μ€ μ¬ν„μ„± κ²€μ¦ μ‹κ°„ κΈ°μ¤€ 2.5μ‹κ°„ μ΄λ‚΄λ΅, 3μ‹κ°„ μ ν•μ„ μ¶©μ΅±ν•©λ‹λ‹¤.  

```bash
root@7c32234d1060:/USER/2022AIChallenge# python predict.py --weights submission/tune_last.pt
predict: weights=['submission/tune_last.pt'], data=data/dataset.yaml, batch_size=16, conf_thres=0.01, iou_thres=0.7, imgsz=1536, project=runs/val, name=official, workers=8, device=, half=False
YOLOv5 π€ f6d6793 Python-3.8.5 torch-1.7.1 CUDA:0 (Tesla T4, 15110MiB)

Fusing layers... 
Model summary: 574 layers, 140095828 parameters, 0 gradients
test: Scanning '/USER/2022AIChallenge/../dataset/test_imgs.cache' images and labels... 0 found, 19521 missing, 0 empty, 0 corrupt: 100%|β–β–β–β–β–β–β–β–β–β–| 19521/19521 [00:00<?, ?it/s]                                                                        
               Class     Images     Labels          P          R     mAP@.5    mAP@.75 mAP@.5:.95:   4%|β–         | 54/1221 [05:49<2:09:41,  6.67s/it]
```

- - -

## Reproducibility

λ³Έ repoμ—μ„λ” `utils/general.py`μ—μ„ `init_seeds` ν•¨μλ¥Ό ν†µν•΄ Reproducibilityλ¥Ό μ μ–΄ν•©λ‹λ‹¤.

```python
def init_seeds(seed=0):
    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html
    # cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible
    import torch.backends.cudnn as cudnn
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed) # if use multi-GPU
    cudnn.benchmark, cudnn.deterministic = (False, True) if seed == 0 else (True, False)
```

κ·Έλ¬λ‚ PyTorchλ” κ³µμ‹μ μΌλ΅ μ™„λ²½ν Reproducibilityλ¥Ό μ μ–΄ν•  μ μ—†λ‹¤κ³  ν•©λ‹λ‹¤. λ€ν‘μ μΌλ΅ CUDA ν•¨μλ¥Ό μ‚¬μ©ν•λ” PyTorch ν•¨μλ“¤ μ¤‘ nondeterministicν• ν•¨μλ“¤μ΄ μ΅΄μ¬ν•©λ‹λ‹¤. λ³Έ repoλ” μ΄ μ¤‘ λ¶κ°€ν”Όν•κ² `torch.nn.funcional.interpolate()`λ¥Ό μ‚¬μ©ν•κ³  μμ–΄, μ™„λ²½ν• Reproducibility μ μ–΄κ°€ λ¶κ°€ν•©λ‹λ‹¤.
- λ νΌλ°μ¤: [Reproducible PyTorchλ¥Ό μ„ν• randomness μ¬λ°”λ¥΄κ² μ μ–΄ν•κΈ°!](https://hoya012.github.io/blog/reproducible_pytorch/)

μ‹¤μ λ΅ κ°™μ€ μ΅°κ±΄μ—μ„ ν•™μµμ„ μ§„ν–‰ν•΄λ„ μ΅°κΈμ”© λ‹¤λ¥΄κ² κ³„μ‚°λλ” λ¨μµμ„ ν™•μΈν•  μ μμ—μµλ‹λ‹¤.
- μ„μ— μ–ΈκΈ‰ν• `torch.nn.funcional.interpolate()` ν•¨μ, νΉμ€ obj lossλ¥Ό κ³„μ‚°ν•λ” κ³Όμ •μ—μ„ μ—°μ‚°λλ” `bcewithlogitsloss`μ—μ„ Reproducibilityκ°€ κΉ¨μ§€λ” κ²ƒμΌλ΅ μ¶”μ •λ©λ‹λ‹¤.

λ•λ¬Έμ— λ³Έ repoμ—μ„λ” μ™„λ²½ν• Reproducibilityκ°€ κµ¬ν„λμ–΄ μμ§€λ” μ•μ€ μ μ„ κ°μ• λ¶€νƒλ“λ¦½λ‹λ‹¤. κ·Έλ¬λ‚ μ„μ μ‘μ—…λ“¤λ΅ μµλ€ν•μ Reproducibilityλ” ν™•λ³΄ν•μ—¬, λ¶κ°€ν”Όν• μ •λ§ μ‘μ€ μ°¨μ΄λ“¤λ§μ΄ μ΅΄μ¬ν•©λ‹λ‹¤.  

- - -

## Reference

- [yolov5](https://github.com/ultralytics/yolov5)